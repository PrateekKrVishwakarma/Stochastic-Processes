\documentclass[a4paper,10pt]{article}
\include{header}
\title{Lecture 8: Equilibrium Renewal Processes and Renewal Reward Processes}
\author{Parimal Parag}

\begin{document}
\maketitle
\section{Renewal theory Contd. -- Delayed Renewal processes }

\subsection{Example:}
Consider two coins and suppose  that each time is coin flipped, it lands tail with some unknown probability $p_i,~i=1,2.$ We are interested in coming up with a strategy that ensures that long term proportion of tails is $\min\{p_1,~p_2\}.$ One strategy is as follows: Set $n = 1$. In the $n^\text{th}$ round of coin flipping, flip the first coin till $n$ consecutive tails are obtained. Then flip the second coin till $n$ consecutive tails are obtained. Increment $n$ and repeat. \\

{\bf Claim.} $\lim_{m \to \infty} \frac{\# \mbox{tails in the first
    $m$ tosses}}{m} = \min\{p_1, p_2\}$ with probability $1$.\\

The proof is as follows. Let $p=\max\{p_1,p_2\}$ and $\alpha p
=\min\{p_1,p_2\}$. There is nothing to prove if $\alpha = 1$, so let
$\alpha < 1$. Call the coin with $P(T)=p$, the bad coin and the other,
the good coin. Let $B_n$ denote the number of flips in the
$n^\text{th}$ round of tossing the bad coin, and $G_n$ the number of
flips in the $n^\text{th}$ round of tossing the good coin. We first
prove the following lemma.
 \begin{lem}
   For any $\epsilon > 0$ with $\epsilon^{-1} \in \N$,
 $P(B_n \geq \epsilon G_n ~\text{for infinitely many rounds}~ n)=0$.
 \end{lem} 
 \begin{proof}
   For any $n \in \mathbb{N}$,
 \begin{flalign*}
   P\left(G_n \leq  \frac{B_n}{\epsilon}\right)&=\mathbb{E}[P(G_n \leq \frac{B_n}{\epsilon}|B_n)]\\
   &=\mathbb{E}[ \sum_{i=1}^{\frac{B_n}{\epsilon}}P(G_n = i |B_n)]\\
   &\leq\mathbb{E}[ \sum_{i=1}^{\frac{B_n}{\epsilon}} (\alpha p)^n]\\
   &= \mathbb{E}[{\frac{B_n}{\epsilon}}](\alpha p)^n \\
   &=\epsilon^{-1} \left( \sum_{i=1}^n \frac{1}{p^{i}}\right) (\alpha
   p)^n = \epsilon^{-1} \frac{p^{-n} - 1}{1 - p} (\alpha p)^n,
 \end{flalign*}
 where the inequality follows from the fact that $\{G_m = i\}$ implies
 that $i \geq m$ and that in cycle $m$, the coin flips numbered
 $i-m+1$ to $i$ are all tails. Hence,
 \[ \sum_{n=1}^\infty P\left(G_n \leq \frac{B_n}{\epsilon}\right) \leq
 \epsilon^{-1} \sum_{n=1}^\infty \frac{\alpha^{n}}{1 - p} < \infty.\]
 By the Borel-Cantelli lemma, it
 follows that $P(B_n \geq \epsilon G_n \text{for infinitely many
   $n$}) = 0$.
 \end{proof}
 With probability $1$, all but a finite number of rounds have at most
 an $\epsilon$ fraction of bad coin tosses, implying that $\lim_{m \to
   \infty} \frac{\# \mbox{bad coin tosses in the first $m$ tosses}}{m}
 \leq \epsilon$. Now taking a decreasing sequence $\epsilon_k = 1/k$,
 $k = 1, 2, 3, \ldots$, and using the continuity of probability, we
 get that with probability $1$, $\lim_{m \to \infty} \frac{\#
   \mbox{bad coin tosses in the first $m$ tosses}}{m} = 0$. This
 proves the claim using the strong law of large numbers for tosses of
 the good coin.

 \subsection{Distribution of the Last Renewal Time for a Delayed Renewal Process}
 In the same manner as we derived the key lemma for the last renewal
 time distribution of a standard renewal process, we can show for a
 delayed renewal process:
 \begin{flalign*}
 P(S_{N(t)} \leq s)&=G^c(t) P(S_{N(t)} \leq s|S_{N(t)=0})+\int_{0}^{t}P(S_{N(t)} \leq s|S_{N(t)=s})F^c(t-u)dm(u)\\
 &= G^c(t) +\int_{0}^{s}F^c(t-u)dm(u).
 \end{flalign*}
 Let $F_e(x)=\frac{\int_{0}^{x}F^c(y)dy}{\mu},~ x \geq 0$, known as
 the \textit{equilibrium distribution} of $F$. Observe that (a) the
 moment generating function of $F_e(x)$ is $\tilde{F}_e(s) =
 \frac{1-\tilde{F}(s)}{s\mu}$, and (b) $F_e$ is the limiting
 distribution of the age and the excess time for the renewal process
 governed by $F$. If $G=F_e,$ then the delayed renewal process is
 called the \textit{equilibrium renewal process}. Suppose we start
 observing a renewal process at some arbitrary time $t$. Then, the
 observed renewal process is the equilibrium renewal process. Let
 $Y_D(t)$ denote the excess time for the (delayed) equilibrium renewal
 process.
 \begin{thm}
 For the equilibrium renewal process,
 \begin{enumerate}
 \item $m_D(t) =\frac{t}{\mu}$.\\
 \item $P(Y_D(t) \leq x) = F_e(x)$.\\
 \item $\{N_D(t): t \geq 0\}$ has stationary increments.
  \end{enumerate}
\begin{proof}
To prove i), observe that $\tilde{m_D(s)}=\frac{\tilde{G}(s)}{1-\tilde{F}(s)} = \frac{1}{s\mu}$. Hence, $m_D(t)=\frac{t}{\mu}$.\\
ii) 
\begin{flalign*}
P(Y_D(t) >x) &= P(Y_D(t) >x|S_{N(t)=0})P(S_{N(t)=0}) +P(Y_D(t) >x|S_{N(t)=s})F^c(t-s)\frac{ds}{\mu}\\
 &= P(X >t+x,X>t) +P(X_2 >t+x-s|X_2 >t-s)F^c(t-s)\frac{ds}{\mu}\\
&= F^c(t+x)+\int_{0}^{t}F^c(t+x-s)\frac{ds}{\mu} = F_e^c(x).
\end{flalign*}
iii) $N_D(t+s)-N_D(s) =$ Number of renewals in time interval of length $t$. When we start observing at $s$, the observed renewal process is delayed renewal process with initial distribution being the original distribution.
\end{proof}
\end{thm}

\subsection{Renewal Reward Process}
\textbf{Definition:} A renewal process $\{N(t), t \geq 0\}$ with inter arrival times $\{X_n: n \in \mathbb{N}\}$ having distribution $F$ and rewards $\{R_n: n \in \mathbb{N}\}$ where $R_n$ is the reward at the end of $X_n$. Let $(X_n,R_n)$ be iid. Then $R(t)=\sum_{i=1}^{N(t)}R_i$ is reward process. 
\begin{thm}
Let $\mathbb{E}[|R|]$ and $\mathbb{E}[|X|]$ be finite.
\begin{enumerate}
\item $\lim_{t \rightarrow \infty} \frac{R(t)}{t} = \frac{\mathbb{E}[R]}{\mathbb{E}[X]} ~a.s.$
\item  $\lim_{t \rightarrow \infty} \frac{\mathbb{E}[R(t)]}{t} = \frac{\mathbb{E}[R]}{\mathbb{E}[X]}$.
\end{enumerate}
\end{thm}

\begin{proof}
\begin{flalign*}
R(t)&=\sum_{i=1}^{N(t)}R_i\\
&=(\frac{t}{N(t)} \sum_{i=1}^{N(t)}R_i) \frac{N(t)}{t}.
\end{flalign*}
Hence by Strong Law of Large Numbers, $\lim_{t \rightarrow \infty} \frac{R(t)}{t} = \frac{\mathbb{E}[R]}{\mathbb{E}[X]} ~a.s.$\\
To prove the second part, \\

$\mathbb{E}[R(t)]= \mathbb{E}[\sum_{i=1}^{N(t)}R_i)] = (m(t)+1)\mathbb{E}[R]-\mathbb{E}[R_{N(t)+1}]$. Let $g(t)=\mathbb{E}[R_{N(t)+1}].$ 
\begin{flalign*}
g(t)&=\mathbb{E}[R_{N(t)+1}1\{S_{N(t)}=0\}]+\mathbb{E}[R_{N(t)+1}1\{S_{N(t)}>0\}]\\
&=\mathbb{E}[R_1|X_1>t]P(X_1>t)+\int_{0}^{t}\mathbb{E}[R_1|X>t-u]F^c(t-u)dm(u).
&= h(t)+\int_{0}^{t}h(t-u)dm(u).
\end{flalign*}

where $h(t)=\mathbb{E}[R_1|X>t]P(X_1>t) \leq E|R_1|$ $\forall
t$. Since $\mathbb{E}[|R_1|]<\infty$, as $t \rightarrow \infty,$ $h(t)
\rightarrow 0$ as $t \rightarrow \infty.$ Hence, choosing $T$ such
that $|h(u)| \leq \epsilon$ $\forall u \geq T$, we have for all $t
\geq T$ that
\begin{flalign*}
\frac{|g(t)|}{t} &\leq \frac{|h(t)|}{t} +\int_{0}^{t-T}\frac{|h(t-s)|}{t}dm(s)+\int_{t-T}^{T}\frac{|h(t-s)|}{t}dm(s)\\
&\leq \frac{\epsilon}{t}+ \frac{\epsilon m(t-T)}{t}+ \frac{\mathbb{E}[|R_1|]}{t} (m(t)-m(t-T)).
\end{flalign*}
Hence $\lim_{t \rightarrow \infty}\frac{g(t)}{t}= \epsilon/EX$ by the
elementary renewal theorem, and the result follows since $\epsilon >
0$ can be arbitrary.
 \end{proof}

 \textbf{Remarks:}
 \begin{enumerate}
 \item $R_{N(t)+1}$ has different distribution than $R_1$.
 \item $R(t)$ is the gradual reward during a cycle, 
 \begin{flalign*}
 \frac{\sum_{n=1}^{N(t)}R_n}{t} \leq  \frac{R(t)}{t} \leq \frac{\sum_{n=1}^{N(t)+1}R_n}{t}.
 \end{flalign*}
 \end{enumerate}
 
 \subsubsection{Example:} Suppose for an alternating renewal process, we earn at a rate of one per unit time  when the system is on and the reward for a cycle is the the time system is ON during that cycle.\\
 Amount of on time in $\frac{[0,t]}{t} = \lim_{t \rightarrow \infty} \frac{R(t)}{t}=\frac{\mathbb{E}[X]}{\mathbb{E}[X]+\mathbb{E}[Y]} = \lim_{t \rightarrow \infty}P(\text{on at time t})$. 
\end{document}