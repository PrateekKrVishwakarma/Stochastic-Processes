\documentclass[12,a4paper,onecolumn]{article}
%\usepackage{amsmath}
\usepackage[fleqn]{amsmath}
\usepackage[pdftex]{graphicx}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{epstopdf}
%\usepackage[T1]{fontenc}
%\usepackage[utf8]{inputenc}
%\usepackage{babel}
%\usepackage{geometry}
%\usepackage{float}
%\usepackage{amsfonts}
%\usepackage{amscd}
\newtheorem{theorem}{Theorem}
\newtheorem{claim}{Claim}
\usepackage{tabularx}
\begin{document}
\title{Stochastic Processes and Queueing Theory}
\author{Assignment 2}
\maketitle

Notations: 
\begin{enumerate}
\item $X_1,~X_2,\hdots$ i.i.d non negative random variables with distribution $F$. $S_n=\sum_{k=1}^{n}X_k$.\\
\item $N(t)$ is the number of arrivals till time $t$ excluding the one at zero. $m(t)=E[N(t)],~\mu=E[X_1]$.\\
\end{enumerate}

\textbf{Question 1.} Show that $P(X_{N(t)+1}\geq x)\geq \bar{F}(x)$ (where $\bar{F}(.)$ is the complementary cdf). Thus also show that $E[(X_{N(t)+1})^m]\geq E[X^m]$ for any positive integer $m$. Compute $P(X_{N(t)+1}\geq x)$ for $X_i \sim exp(\lambda)$.

\textbf{Solution 1.  a)} To show that $P(X_{N(t)+1}\geq x)\geq \bar{F}(x)$,  \\
\begin{align*}
P(X_{N(t)+1}< x)&=P(X_{N(t)+1}< x,S_1\leq t)+P(X_{N(t)+1}< x, S_1>t)\\
&=\int_{u=0}^{t}P(X_{N(t)+1}< x|S_1=u)dF_{S_1}(u)+ \int_{u=t}^{\infty} P(X_{1}< x|S_1=u)dF_{S_1}(u)\\
&=\int_{u=0}^{t}P(X_{N(t-u)+1}< x)dF_{S_1}(u)+ \int_{u=t}^{\infty} I_{\{x\geq u \}} dF_{S_1}(u)
\end{align*}
If $x>t$,
\begin{align*}
P(X_{N(t)+1}< x)&=\int_{u=0}^{t}P(X_{N(t-u)+1}< x)dF_{S_1}(u)+ \int_{u=t}^{x}dF_{S_1}(u)\\.
P(X_{N(t)+1}\geq x)&=1-P(X_{N(t)+1}< x)\\
&=\int_{u=0}^{t}dF_{S_1}(u)+\int_{u=t}^{x}dF_{S_1}(u)+\int_{u=x}^{\infty}dF_{S_1}(u)\\
&-\int_{u=0}^{t}P(X_{N(t-u)+1}< x)dF_{S_1}(u)-\int_{u=t}^{x}dF_{S_1}(u)
\end{align*}
\begin{align*}
&=\int_{u=0}^{t}dF_{S_1}(u)+\int_{u=x}^{\infty}dF_{S_1}(u)-\int_{u=0}^{t}P(X_{N(t-u)+1}< x)dF_{S_1}(u)\\
&=\int_{u=0}^{t}(1-P(X_{N(t-u)+1}< x))dF_{S_1}(u) +\int_{u=x}^{\infty}dF_{S_1}(u)\\
&\geq \int_{u=x}^{\infty}dF_{S_1}(u)=P(X_1\geq x).\\
 \end{align*}
 
 If $x\leq t$,
 
 \begin{align*}
P(X_{N(t)+1}< x)&=\int_{u=0}^{t}P(X_{N(t-u)+1}< x)dF_{S_1}(u)+ \int_{u=t}^{\infty}I_{\{x\geq u \}} dF_{S_1}(u)\\
&=\int_{u=0}^{t}P(X_{N(t-u)+1}< x)dF_{S_1}(u)\\
&\geq \int_{u=0}^{x}P(X_{N(t-u)+1}< x)dF_{S_1}(u)
\end{align*}

\begin{align*}
P(X_{N(t)+1}\geq x)&=1-P(X_{N(t)+1}< x)\\
&=\int_{u=0}^{x}dF_{S_1}(u)+\int_{u=x}^{\infty}dF_{S_1}(u)-\int_{u=0}^{x}P(X_{N(t-u)+1}< x)dF_{S_1}(u)\\ 
&=\int_{u=0}^{x}(1-P(X_{N(t-u)+1}< x))dF_{S_1}(u)+\int_{u=x}^{\infty}dF_{S_1}(u)\\
&\geq \int_{u=x}^{\infty}dF_{S_1}(u)=P(X_1\geq x).\\
 \end{align*}
 
\textbf{b)} To show part b) we use the following expectation formula for non negative random variables.\\

\begin{align*}
 E[X^m]&=E[ (\int_{t=0}^{X}mt^{(m-1)}dt)]\\
&=\int_{x=0}^{\infty}\int_{t=0}^{x}mt^{(m-1)}dtdF(x)\\
&=\int_{t=0}^{\infty}\int_{x=t}^{\infty}dF(x)mt^{(m-1)}dt\\
&=\int_{t=0}^{\infty}P(X>t)mt^{(m-1)}dt.
\end{align*}

Now, $E[(X_{N(t)+1})^m]=\int_{u=0}^{\infty}P(X_{N(t)+1}>u)mu^{(m-1)}du \geq \int_{t=0}^{\infty}P(X_{1}>u)mu^{(m-1)}du=E[X_{1}^m]$.

\textbf{c)} 

\begin{align*}
P(X_{N(t)+1}\geq x)&=\int_{u=0}^{\infty} P(X_{N(t)+1}\geq x,A(t)> u)du\\
&=\int_{u=0}^{\infty} P(X_{N(t)+1}\geq x|A(t)> u)dF_{A(t)}(u)\\
&=\int_{u=0}^{x} P(X_{N(t)+1}\geq x|A(t)> u)dF_{A(t)}(u)+\int_{u=x}^{\infty} P(X_{N(t)+1}\geq x|A(t)> u)dF_{A(t)}(u)\\
&=\int_{u=0}^{x} P(X_{1}\geq x|X_1> u)dF_{A(t)}(u)+\int_{u=x}^{\infty}  1 dF_{A(t)}(u)\\
\end{align*}
\begin{align*}
&=  \int_{u=0}^{x}\frac{P(X_{1}\geq x)}{P(X_1> u)}dF_{A(t)}(u)+ e^{-\lambda x}\\
&=  e^{-\lambda x}\int_{u=0}^{x}e^{\lambda u}dF_{A(t)}(u)+ e^{-\lambda x}\\
&=  \lambda x e^{-\lambda x}+ e^{-\lambda x}\\
\end{align*}
 
 As $A(t) \sim exp(\lambda)$. Try proving this from renewal argument.

\textbf{Question 2.} Prove the renewal equation: $m(t)=m(t)*F(t)$.\\

\textbf{Solution 2.}
\begin{align*}
m(t)&=E[N(t)]=E[N(t)\times 1]=E[N(t)(I_{\{S_1\leq t\}}+I_{\{S_1>t\}})]\\
&=E[N(t)I_{\{S_1\leq t\}}]+E[N(t)I_{\{S_1>t\}}]\\
&=E[N(t)I_{\{S_1\leq t\}}]=\int_{u=0}^{t}E[N(t)|{S_1= u}]dF_{S_1}(u)\\
&=\int_{u=0}^{t}E[1+N(t-u)]dF_{S_1}(u)=F(t)+ m(t)*F(t).\\
\end{align*}

\textbf{Question 3.} If $F$ is uniform on $(0,1)$ then show that $m(t)=e^t-1,~0\leq t \leq 1$.\\

\textbf{Solution 3.} If $F\sim$ Uniform$(0,1)$, $dF_{S_1}(u)=du$

\begin{align*}
m(t)&=\int_{u=0}^{t}m(t-u)dF_{S_1}(u)=\int_{u=0}^{t}m(t-u)du=\int_{u=0}^{t}m(u)du.\\
\end{align*}

Together with the initial condition, $m(0)=E[N(0)]=0$, we solve for the above differential equation to get $m(t)=e^t-1,~t\in[0,1].$

\textbf{Question 4.} Consider single server bank in which potential customers arrive at Poisson rate $\lambda$. Customer enters the bank only of the server s free when the customer arrives. Let $G$ denote the service distribution.\\
a). What fraction of time the server is busy?\\
b). At what rate customer enters the bank?\\
c). At fraction of potential customers enter the bank ?\\

\textbf{Solution 4.} The question can be solved by using Renewal Reward Theorem (RRT)(is a direct consequence of the Renewal theorem. ) a). Consider a renewal period. It consists of idle and busy periods. Let the fraction of time the server is busy be the reward during the cycle. From RRT, the answer is $\frac{\int x^2dG(x)}{(\lambda^{-1})+\int x^2dG(x)}$.\\
b).Let $L_k$ denote the fraction of lost customers in $jth$ cycle. From RRT, rate at which customers not entering the system is $\lambda_l=\frac{\lambda \int x^2dG(x)]}{(\lambda^{-1})+\int x^2dG(x)}$. From this  we get the required rate=$\lambda-\lambda_l$ .\\
c). The reward for this case, during a cycle (in terms of customers, not time) is $1$. The total arrival is $L_k+1$ during cycle $k$. From RRT, the required rate is $\frac{1}{1+\lambda \int x^2 dG(x)}$.\\

\textbf{Question 5.} Find the renewal equation for $E[A(t)]$. Then also find $\lim_{t \rightarrow \infty} E[{A(t)}]$.\\

\textbf{Solution 5.} Let $g(t)=E[A(t)].$

\begin{align*}
g(t)&=E[A(t)]=E[A(t)\times 1]=E[A(t)(I_{\{S_1\leq t\}}+I_{\{S_1>t\}})]\\
&=E[A(t)I_{\{S_1\leq t\}}]+E[A(t)I_{\{S_1>t\}}]\\
&=E[A(t)I_{\{S_1\leq t\}}]+E[tI_{\{S_1>t\}}]\\
&=\int_{u=0}^{t}E[A(t)|{S_1= u}]dF_{S_1}(u)+tP(S_1>t)\\
&=\int_{u=0}^{t}E[A(t-u)]dF_{S_1}(u)+tP(S_1>t)=g(t)*F(t)+h(t).\\
\end{align*}
where $h(t)=tP(S_1>t)$. We know that the solution to the above renewal equation (which is the solution to part a) of the question) is $g(t)=m(t)*h(t)+h(t)$. Now, we are interested in finding the limit $\lim_{t \rightarrow \infty} g(t)$. Recall, Key Renewal Theorem (KRT) which says that, if $h(.)$ is directly Riemann integrable (dRi), then, 

\begin{align*}
\lim_{t \rightarrow \infty} g(t)*h(t)=\frac{\int_{u=0}^{\infty}h(u)du}{E[X_1]}.\\
\end{align*}

Hence, if the distribution function of $S_1$ is such that $h(t)$ is dRi ((eg. Exponential distribution. A sufficient condition for dRi is $E[X^2]<\infty$. This is easy to see as $\int_{t=0}^{\infty}h(t)=\frac{1}{2}E[X^2]$), then, 

\begin{align*}
\lim_{t \rightarrow \infty} g(t)*h(t)&=\frac{\int_{u=0}^{\infty}h(u)du}{E[X_1]}\\
&=\frac{1}{E[X_1]}\int_{u=0}^{\infty}uP(S_1>u)du\\
&=\frac{1}{E[X_1]}\int_{u=0}^{\infty}u\int_{s=u}^{\infty}dF_{S_1}(s)du\\
&=\frac{1}{E[X_1]}\int_{s=0}^{\infty}\int_{u=0}^{s}udF_{S_1}(s)du\\
&=\frac{1}{E[X_1]}\int_{s=0}^{\infty}\int_{u=0}^{s}udu dF_{S_1}(s)\\
&=\frac{1}{E[X_1]}\int_{s=0}^{\infty}[\frac{u^2}{2}]_{u=0}^{s} dF_{S_1}(s)\\
&=\frac{1}{E[X_1]}\int_{s=0}^{\infty}s^2 dF_{S_1}(s)=\frac{E[X_1^2]}{2E[X_1]}.\\
\end{align*}

Also, here we have h(t) to be a non-negative function. Hence (from class notes dated 28-01-2014, Tuesday, second lecture on Renewal process), if $h(t)$ is dRi, $\lim_{t\rightarrow \infty}h(t)=0$. Thus whenever the distribution function $F$ is such that $h(.)$ is dRi, the solution to part b) is $\frac{E[X_1^2]}{2E[X_1]}$.

\textbf{Question 7.} Consider a delayed renewal process $\{N_D(t), t\geq 0\}$ whose first interarrival time has distribution $G$ and the others have distribution $F$. Let $m_D(t)=E[N_D(t)].$\\
a) Prove that, $m_D(t)=G(t)+m(t)*G(t)$, where $m(t)=\sum_{n=1}^{\infty}F^{*n}(t)$.\\
b) Let $A_D(t)$ denote the age time at time $t$. Show that if $F$ is non lattice with $\int x^2dF(x)<\infty$ and $t\bar{G}(t)\rightarrow 0$ at $t \rightarrow \infty$, then


\begin{align*}
E[A_D(t)] \rightarrow \frac{\int_{x=0}^{\infty}x^2dF(x)}{2\int_{x=0}^{\infty}xdF(x)}
\end{align*}

\textbf{Solution 7.} 
\begin{align*}
m_D(t)&=E[N_D(t)]=E[N_D(t)\times 1]=E[N_D(t)(I_{\{S_1\leq t\}}+I_{\{S_1>t\}})]\\
&=E[N_D(t)I_{\{S_1\leq t\}}]+E[N_D(t)I_{\{S_1>t\}}]\\
&=E[N_D(t)I_{\{S_1\leq t\}}]=\int_{u=0}^{t}E[N_D(t)|{S_1= u}]dG_{S_1}(u)\\
&=\int_{u=0}^{t}E[1+N(t-u)]dG_{S_1}(u)=G(t)+m(t)*G(t).\\
\end{align*}

\begin{align*}
g(t)&=E[A_D(t)]=E[A_D(t)\times 1]=E[A_D(t)(I_{\{S_1\leq t\}}+I_{\{S_1>t\}})]\\
&=E[A_D(t)I_{\{S_1\leq t\}}]+E[A_D(t)I_{\{S_1>t\}}]\\
&=E[A_D(t)I_{\{S_1\leq t\}}]+E[tI_{\{S_1>t\}}]\\
&=\int_{u=0}^{t}E[A_D(t)|{S_1= u}]dG_{S_1}(u)+tP(S_1>t)\\
&=\int_{u=0}^{t}E[A(t-u)]dG_{S_1}(u)+tP(S_1>t)=\tilde{g}(t)*G(t)+h(t).\\
\end{align*}
where $h(t)=tP(S_1>t)=t\bar{G}(t)$.

From KRT,

\begin{align*}
\lim_{t \rightarrow \infty} \tilde{g}(t)*h(t)=\frac{\int_{u=0}^{\infty}h(u)du}{E[X_2]}.\\
\end{align*}

Also from the hypothesis given, $h(t)$ is dRi. Hence,
\begin{align*}
\lim_{t \rightarrow \infty} \tilde{g}(t)*h(t)&=\frac{\int_{u=0}^{\infty}h(u)du}{E[X_2]}\\
&=\frac{1}{E[X_2]}\int_{u=0}^{\infty}uP(S_2>u)du\\
&=\frac{1}{E[X_2]}\int_{u=0}^{\infty}u\int_{s=u}^{\infty}dF_{S_2}(s)du\\
&=\frac{1}{E[X_2]}\int_{s=0}^{\infty}\int_{u=0}^{s}udF_{S_2}(s)du\\
&=\frac{1}{E[X_2]}\int_{s=0}^{\infty}\int_{u=0}^{s}udu dF_{S_2}(s)\\
&=\frac{1}{E[X_2]}\int_{s=0}^{\infty}[\frac{u^2}{2}]_{u=0}^{s} dF_{S_2}(s)\\
&=\frac{1}{E[X_2]}\int_{s=0}^{\infty}s^2 dF_{S_2}(s)=\frac{E[X_2^2]}{2E[X_2]}.\\
\end{align*}

\textbf{Question 8.} Consider a $GI/GI/1$ queue. Interarrival times $\{A_n\}$ are iid and service times $\{S_n\}$ are iid with $E[S_n]<E[A_n]<\infty$. Let $V(t)$ be the virtual service time in the queue at time t $\triangleq$ sum of remaining service time of all customers present in the system at time $t$. Show that,\\
a).  

\begin{align*}
V \triangleq \lim_{t \rightarrow \infty} \frac{1}{t}\int_{0}^{t}V(s)ds
\end{align*}
 exists a.s and is a constant. \\
 
 b). Let $D_n$ the amount of time $n^{\text{th}}$ customer waits in the queue. Define
 
 \begin{align*}
W_Q \triangleq \lim_{n \rightarrow \infty} \frac{D_1+D_2 \hdots D_n}{n}
\end{align*}
Show that $W_Q$ exists a.s and is a constant. \\

c). Show that $V=\lambda E[Y]W_Q+\lambda \frac{E[Y^2]}{2}$ where $\frac{1}{\lambda}=E[A_n]$ and $Y$ has the distribution of service time.

\textbf{Solution 8.} To solve this question, we have to use the regenerative argument or implicitly, Renewal Reward Theorem (RRT). Here, one could view, $R(t)=\int_{0}^{t}V(s)$ as the total reward earned till time $t$. Now, RRT gives 
\begin{align*}
\frac{R(t)}{t}\stackrel{t \rightarrow \infty}{\rightarrow}\frac{E[\text{Reward earned in a cycle}]}{E[\text{Cycle duration}]}
\end{align*} 
This proves part a).\\

For part b), to prove that the limit exists, consider the following:

The waiting time $D_n$ of $n^{\text{th}}$ customer has the following recursive structure( see the figure below): 

\begin{align*}
D_n=\max\{0,D_{(n-1)}+S_n-A_{(n-1)}\}.
\end{align*} 
 \begin{figure}[h]
 \hspace{40pt}
\includegraphics[scale=.45]{gigi1}
\hspace{40pt}\caption{Recursive formula for waiting time.}
 \end{figure}
 
 Let $\alpha_n=S_n-A_{(n-1)}$. Also, $\max(0, \max(0,b)+c)=\max(0,c,b+c)$. Now, we can write the recursion as follows:\\
 
\begin{align*}
D_n&=\max\{0,D_{(n-1)}+S_n-A_{(n-1)}\}\\
&=\max\{0,\max\{0,D_{(n-2)}+S_{(n-1)}-A_{(n-2)}\}+S_n-A_{(n-1)}\}\\
&=\max\{0,\max\{0,D_{(n-2)}+\alpha_{(n-1)} \}+\alpha_n\}\\
&=\max\{0,D_{(n-2)}+\alpha_{(n-1)}+\alpha_n,\alpha_n \}\\
&=\max\{0,\sum_{k=1}^{n}\alpha_k,\sum_{k=1}^{n-1}\alpha_k,\hdots\}\\
\end{align*}
 
 Thus, if we denote $\max(0,x)$ as $x^+$, $\lim_{n \rightarrow \infty}D_n$ is equal to $D \triangleq (\sup_{n \geq 1}\sum_{k=1}^{n}\alpha_k)^+$. Now, note that, $E[\alpha_n]=E[S_n-A_{(n-1)}]<0$ (given). And, $\alpha_i$s are iid with finite mean. Hence, from SLLN, 
 
 \begin{align*}
\frac{1}{n}\sum_{k=1}^{n}\alpha_k \rightarrow -\epsilon, 
\end{align*}

where, $\epsilon $ is some positive quantity. Thus, $\sum_{k=1}^{n}\alpha_k$ converges to $-\infty$ a.s. Hence, the supremum of it should be finite. thus we proves the a.s existence of a finite limit of $D_n$. Now, part b) asks for the limit of Cesaro sum of the $D_n$. Thus shows the almost sure existence of $W_Q$. 

to show part c), we need to compute the expression in part a). The renewal instants for the process are at times when $V(t)=0$. Let $C$ denote the \textbf{inter} renewal time. Let $\tilde{N}$ denote the number of arrivals during $C$ duration. Hence, $E[C]=E[\sum_{k=1}^{\tilde{N}}A_k]=E[\sum_{k=2}^{\tilde{N}+1}A_k]= E[\tilde{N}+1]E[A_k]=\frac{E[\tilde{N}+1]}{\lambda}$. Similarly we are interested in computing the numerator in part a) of  the problem. See the figure below. During inter renewal period, we have the following graph for the virtual waiting time $V(t)$. Note that, the  renewal happens once $V(t)$ hits $t$. Thus, total reward during a cycle is the area of the graph which can in turn be found from the areas of triangles and parallelograms. In the figure below, the area is equal to the area of triangles $P_1,P_2,P_3$, $Q_1,Q_2,Q_3$, $R_1,R_2,R_3$ and the area of parallelograms $P_3,Q_2,Q_3,L_1$, $L_1,R_2,R_3,L_2$. The base and altitude of the triangles are the service times. The base of parallelogram is the service time and height is the waiting time. Also, the trianglea have 45 degree angles owing as the virtual waiting time decreases linearly with $t$. In fact, for an interarrival time $[T_m,T_{n-1})$ the virtual waiting time $V(t)=\max\{0,W(T_n-)+S_n-(t-T_n)\}$.

 \begin{figure}[h]
 \hspace{40pt}
\includegraphics[scale=.45]{gigi12}
\hspace{40pt}\caption{Virtual waiting time.}
 \end{figure}
 
 Thus, 
 
 \begin{align*}
E[\text{Reward during cycle}]&=E[\sum_ {k=1}^{\tilde{N}}(\frac{1}{2}S_k^2+D_kS_k)]\\
&=E[\sum_ {k=2}^{\tilde{N}+1}(\frac{1}{2}S_k^2+D_kS_k)]=E[\tilde{N}+1](E[\frac{S_k^2} {2}]+E[S_kD_k])\\
&=E[\tilde{N}+1](E[\frac{Y^2}{2}]+E[Y]W_Q).
\end{align*}

Hence, $V=\lambda E[Y]W_Q+\frac{\lambda}{2}E[Y^2]$.
%&=\int_{u=0}^{\infty}P(X_{N(t)+1}\geq x, S_1 > u)du\\
%&=\int_{u=0}^{p}P(X_{N(t)+1}\geq x, S_1 > u)du+\int_{u=p}^{\infty}P(X_{N(t)+1}\geq x, S_1 > u)du\\
%&\geq  \int_{u=p}^{\infty}P(X_{N(t)+1}\geq x, S_1 > u)du\\
%&= \int_{u=p}^{\infty}P(X_{N(t)+1}\geq x| S_1 > u)P(S_1 > u)du\\
%&= \int_{u=p}^{\infty}P(X_{1}\geq x| S_1 > u)P(S_1 > u)du\\
%&= \int_{u=p}^{\infty}P(X_{1}\geq x| S_1 > u)P(S_1 > u)du\\
%\begin{thebibliography}{30}
%
%\bibitem{guy}
%Guy Keshet, Yossef Steinberg,Neri Merhav, ``Channel Coding in the Presence of Side Information: Subject Review", \textit{NOW Publications}.
%
%\bibitem{erez}
%Uri Erez, Ram Zamir,``Noise Prediction for Channel Coding with Side Information at the
%Transmitter," \textit{IEEE}, 1998.
%
%\bibitem{erez1}
%Uri Erez, Shlomo Shamai (Shitz), Ram Zamir, ``Capacity and Lattice strategies for Cancelling Known Interference," \textit{IEEE TRANSACTIONS ON INFORMATION THEORY}, Nov 2005.
%
%\bibitem{gamal}
%Chris Heegrad, Abbas A. El Gamal, ``On the Capacity of Computer Memory with
%Defects,\textit{IEEE TRANSACTIONS ON INFORMATION THEORY}, VOL. IT - 29, NO. 5, PIMRC, Sept. 1983.
%
%\bibitem{shannon}
%C.E.Shannon, ``Channels with Side Information at the Transmitter", \textit{IBM Journal}, Oct 1958.
%
%\bibitem{lap}
%A. Lapidoth and Y. Stienberg, ``The Multiple Access Channel with Two Independent
%States Each Known Causally to One Encoder," \textit{ISIT, Austin.}, June. 2010.

%\bibitem{caire}
%G. Caire et al., ``On the Capacity of some Channels with Channel State Information," \textit{IEEE Transactions on Information Theory}, 1998.
%
%\bibitem{broad}
%Y. Stienberg, ``Coding for the degraded broadcast channel with random parameters, with causal and noncausal side information",\textit{IEEE Trans. Inform. Theory }, July, 2005.
%
%\bibitem{gamal1}
%A. El Gamal, and T. Weissman, ``Source coding with causal side information at the decoder," ,\textit{Proc. 43rd Annu. Allerton Conf. Communication, Control, and
%Computing, Monticello},pp. 28-30, Sep. 2005.
%
%\bibitem{ziv}
%A. D. Wyner and J. Ziv, ``The rate-distortion function for source coding with
%side information at the decoder," ,\textit{IEEE Trans. Inform. Theory}, vol. IT-22, no.
%1, pp. 1-10, Jan. 1976.


%\end{thebibliography}
 \end{document}