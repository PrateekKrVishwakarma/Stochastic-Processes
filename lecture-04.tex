\documentclass[a4paper,10pt,english]{article}
\input{header}
\title{Lecture 03: Properties of Poisson Process}
\author{}

\begin{document}
\maketitle
\section{Non-Homogeneous Poisson Process}
From the characterization of Poisson process just stated, we can generalize to non-homogeneous Poisson process. In this case, the rate of Poisson process $\lambda$ is time varying. It is not clear from the first two characterizations, how to generalize the definition of Poisson process to the non-homogeneous case. We used third characterization of Poisson process for this generalization. 

\begin{defn}[Non-Homogeneous Poisson Process]\label{defn:NonHomogeneousPoisson} A point process $\{N(t),~t\geqslant 0\}$ is said to be \textbf{non-homogeneous Poisson process} with instantaneous rate $m(t)$ if it has stationary independent increments, and 
 \begin{eqnarray*}\label{eq:NonHomogeneousPoisson}
 \Pr\{N(t)=0\}&=&1-m(t)+o(t). \\
  \Pr\{N(t+\delta)-N(t)=0\} &=& 1-m(t)\delta+o(\delta). \\
   \Pr\{N(t+\delta)-N(t)=1\} &=& m(t)\delta+o(\delta). \\
   \Pr\{N(t+\delta)-N(t)>1\} &=& o(\delta). \\
   \end{eqnarray*}
\end{defn}

\begin{prop}[Non-Homogeneous Distribution] Distribution of non-homogeneous Poisson process $N(t)$ with instantaneous rate $m(t)$ is given by
 \begin{align*}
 \Pr\{N(t)=n\}=\frac{(\bar{m}(t))^n}{n!}e^{-\bar{m}(t)},
 \end{align*}
where $\bar{m}(t)$ is the cumulative rate till time $t$, i.e. $\bar{m}(t)=\int_{0}^{t}m(s)ds$. 
\end{prop}
\begin{proof}
Let's denote $f(t) = \Pr\{N(t)=0\}$. Further, from independent increment property of $N(t)$, we notice that $\{N(t+\delta) = 0\}$ is intersection of two independent events given below, 
\begin{align*}
\{N(t+\delta)=0\} \iff \{N(t)=0\}\cap\{N(t+\delta)-N(t)=0\}.
\end{align*}
From Definition~\ref{defn:NonHomogeneousPoisson}, it follows that
\begin{align*}
 f(t+\delta) = f(t)[1 - m(t)\delta + o(\delta)].
\end{align*}
Re-arranging the terms in the above align, dividing by $\delta$, and taking limit as $\delta \downarrow 0$, we get 
\begin{align*}
f'(t) = -m(t)f(t).
\end{align*}
Since $f(0) = 1$, it can be verified that $f(t) = \exp(-\bar{m}(t))$ is solution for $f(t)$.
%\begin{eqnarray*}
  %f(t+\triangle) &=& \Pr\{N_{t+\triangle}=0] \\
   %&=&  \Pr\{N(t)=0, N_{t+\triangle}-N(t)=0]\\
   %&\stackrel{(a)}{=}& \Pr\{N(t)=0] \Pr\{N_{t+\triangle}-N(t)=0]\\
   %&=& f(t)[1-m(t)\triangle +o(\triangle)].\\
%\frac{f(t+\triangle)-f(t)}{\triangle} &=& -m(t) f(t) +f(t) \frac{0(\triangle)}{\triangle}. \\
  %\lim_{\triangle\downarrow 0}\frac{f(t+\triangle)-f(t)}{\triangle} &=& -m(t) f(t) \\
 %\frac{d f(t)}{t} &=& -m(t) f(t),  \\
 %\end{eqnarray*}
 %where (a) follows from independent increment property. Since, $\overline{m}(t)=\int ^{t}_{0} m(s) ds $, $f(t)=\Pr\{N(t)=0]$, $ f(0)=\Pr\{N_{0}=0] =1$ the solution of the differential align can be verified to be $f(t)=e^{-\overline{m}(t)}$, as follows: 
 %\begin{eqnarray*}
     %f(0)&=& e^{-\overline{m}(t)}\\
  %&=& e^{-0}=1 \\
  %f'(t) &=& e^{-\overline{m}(t)}\frac{d}{dt} \int^{t}_{0}m(S) ds\\
  %&=& m(t)e^{-\overline{m}(t)}, t\geqslant 0 \\
  %\end{eqnarray*}
  %
  %\begin{eqnarray*}
  %\Pr\{N_{t+\triangle}-N(t)=0] &=& 1-m(t)\triangle +o(\triangle) \\
  %\Pr\{N_{\triangle}-N_{0}=0] &=& 1-m(0)\triangle +o(\triangle) 
  %\end{eqnarray*}
  %Since $ N_{0}=0$, 
  %\begin{eqnarray*}
   %\Pr\{N_{\triangle} =0]&=& 1-m(0)\triangle +0(\triangle) \\
  %\lim_{\triangle\downarrow 0}f(\triangle) &=& f(0)=1.
%\end{eqnarray*}
We have shown $\Pr\{N(t)=0\} = \exp(-\bar{m}(t))$. By induction, we can show the result for any $n$.
\end{proof}
\section{Compound Poisson Process}
One of the characterizations of Poisson process was single arrival in an infinitesimal time. We can generalize that definition to have a random number of arrivals $X_n$ at every arrival instant $S_n$.
\begin{defn}[Compound Poisson process] Let $\left\{X_i\right\}$ be \emph{iid} random variables. Let $N(t), t\geq 0$ be a Poisson Process with parameter $\lambda$ independent of $X_i, i\geq 1$. Then the process $X(t)$ defined as
\begin{equation*}
X(t) = \sum_{i=1}^{N(t)} X_i
\end{equation*}
is called a \textbf{compound Poisson process}.
\end{defn}
We derive some properties of compound Poisson Processes in the following.
\subsection{Mean}
\begin{align*}
E[X(t)] = E[\sum_{i=1}^{N(t)} X_i] &= E[E[\sum_{i=1}^{N(t)} X_i|N(t)]] \\
&= \sum_{k=0}^\infty E\left[\sum_{i=1}^{k} X_i|N(t)=k\right]\Pr\{N(t) = k\}\\
&= \sum_{k=0}^\infty \sum_{i=1}^{k} E[X_i]\Pr\{N(t) = k\}\\
&= E[N(t)]E[X_1] = \lambda tE[X_1].
\end{align*}

\subsection{MGF}
We leave it as an exercise to show that $M_{X(t)}(\theta)=E[e^{\theta X(t)}] = e^{(M_X(\theta)-1)\lambda t}$.

\subsection{A nice counterexample}
A Poisson process is not uniquely determined by it's distribution. Let $X_t = Y_t + f(Z+t)$, where $Y_t$ is a Poisson Process and 
\begin{equation*}
f(t) = t 1_{\{t \in \mathbb{Q}\}}.
\end{equation*}
Let $Z$ be a continuous random variable. Then we can show that $\Pr\{X_t \neq Y_t) = 0$. This is true since
\begin{flalign*}
\Pr\{X_t \neq Y_t\} &= \Pr\{\omega \in \Omega: \quad t+Z(\omega) \in \mathbb{Q}\} \\
&= \Pr\{\omega \in \Omega:  Z(\omega) \in \mathbb{Q} - t\} = 0.
\end{flalign*}
The last part follows since $\mathbb{Q}-t$ is a countable set of individual events with probability zero. We can also show that $X(t)$ and $Y(t)$ have same fdds.
\begin{equation*}
  \Pr\{X_{t_1}= Y_{t_1}, X_{t_2}= Y_{t_2}\}
  = \sum_{n_{1},n_{2}}\Pr\{X_{t_1} = n_1, X_{t_2}= n_2, Y_{t_1}=n_1, Y_{t_2}=n_2 \}  = 1.
\end{equation*}
$\{X_{t}(\omega)\}$ can take non-integer values and is not non-decreasing. Two process can have same distribution but sample path behavior can be quite different.
%\section{Compound (Batch) Poisson Process}
%
%\begin{eqnarray*}
%% \nonumber to remove numbering (before each equation)
  %N_{t} &=& \sup \{n: S_{n}\leq t \}  \\
  %\end{eqnarray*}
   %$\overline{N_{t}}$= No of arrivals till time $n$  \\
   %\begin{eqnarray*}
   %\overline{N_{t}}&=& \sum ^{N_{t}}_{k=0}Z_{k}  ~(\text{No. of arrivals till time $n$}).\\
   %\mathbb{E}[\overline{N_{t}}]&=&\mathbb{E}\left[\sum ^{N_{t}}_{k=0}Z_{k}\right]  \\
   %&=& \sum^{\infty}_{n=0}\mathbb{E}\left[\sum ^{N_{t}}_{k=0}Z_{k}|N_{t}-n \right] P[N_{t}=n]\\
   %&=& \sum^{\infty}_{n=0}P[N_{t}=n]\mathbb{E}\left[\sum^{\infty}_{k=0}Z_{k}|N_{t}=n   \right] \\
   %&=& \sum^{\infty}_{n=0} \frac{e^{-\lambda t} (\lambda t)^{n}}{n!} n \mathbb{E}[Z_{1}] \\
   %&=& \mathbb{E} [Z_{1}]\mathbb{E} [N_{t}].
   %\end{eqnarray*}
   %For  $  \alpha>0 $,  \\
   %\begin{eqnarray*}
   %&\mathbb{E}[e^{\alpha \overline{N_{t}}}]=\mathbb{E}\left[e^{\alpha\sum ^{N_{t}}_{k=0}Z_{k}}\right] \\
   %&=& \sum^{\infty}_{n=0}\mathbb{E}\left[ e^{\alpha\sum ^{N_{t}}_{k=0}Z_{k}}| N_{t}=n\right] P[N_{t}=n]\\
   %&=&  \sum^{\infty}_{n=0}\mathbb{E}\left[e^{\alpha\sum ^{n}_{k=0}Z_{k}}\right] P[N_{t}=n]\\
   %&=&\mathbb{E}[\mathbb{E}[e^{\alpha Z_{1}}]^{N_{t}}]\\
  %\mathbb{E} [\beta^{N_{t}}] &=&\sum^{\infty}_{n=0}\frac{(\lambda t)^{n}e^{-\lambda t}}{n!}\beta^{n}\\
   %&=&\sum^{\infty}_{n=0}\frac{(\lambda \beta t)^{n}e^{-\lambda \beta t}}{n!}\lambda (\beta t-t)\\
   %&=& e^{\lambda t (\beta-t)}
   %\end{eqnarray*}
   %\textbf{Example:}\\
%\begin{figure}[h!]
%\center
  %% Requires \usepackage{graphicx}
  %\includegraphics[width=4.5in]{Figures/rate.PNG}\\
 %% \caption{}\label{}
%\end{figure}
%Suppose $\{N_{t}, t \geq 0\}$ Poisson process with rate $\lambda$. 
%
%$\tilde{N_{t}}(w)= N_{t}(w)+f(t+X_{1}(w))$ where $f(t)$=0, if $t$ is irrational and $f(t)$=t, if $t$ is rational.\\
%\begin{eqnarray*}
%% \nonumber to remove numbering (before each equation)
  %P[\tilde{N_{t}}\neq N_{t}] &= P[\omega:t+X_{1}(\omega) \text{is rational}],\\
  %&= P[\omega:X_1(\omega)  \text{is rational} ] =0.
%\end{eqnarray*}
\end{document}
