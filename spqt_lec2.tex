\documentclass[a4paper,10pt]{article}
\usepackage{amsmath,amssymb}
\usepackage{amsthm}
\usepackage{hyperref}
\newtheorem{Thm}{Theorem}
\newtheorem{Lem}{Lemma}
\newtheorem{Prop}{Proposition}

\title{SPQT Lecture 2: Compound Poisson Processes and Renewal Theory}
\author{Prof. Parimal Parag}

\begin{document}
\maketitle
\section{Compound Poisson Process}
Let $\left\{X_i\right\}$ be iid random variables. Let $N(t), t\geq 0$ be a Poisson Process with parameter $\lambda$ independent of $X_i, i\geq 1$. Then the process $X(t)$ defined as
\[X(t) = \sum_{i=1}^{N(t)} X_i\]
is called a Compound Poisson Process.
The following are some properties of Conditional Poisson Processes:
\subsection{Mean}
\begin{flalign*}
E[X(t)] = E[\sum_{i=1}^{N(t)} X_i] &= E[E[\sum_{i=1}^{N(t)} X_i|N(t)]] \\
&= \sum_{k=0}^\infty E\left[\sum_{i=1}^{k} X_i|N(t)=k\right]P(N(t) = k)\\
&= \sum_{k=0}^\infty \sum_{i=1}^{k} E[X_i]P(N(t) = k)\\
&= E[N(t)]E[X_1] = \lambda tE[X_1]
\end{flalign*}

\subsection{MGF}
We leave it as an exercise to show that $M_{X(t)}(\theta)=E[e^{\theta X(t)}] = e^{(M_X(\theta)-1)\lambda t}$.

\subsection{A nice counterexample}
A poisson process is not uniquely determined by it's distribution. Let $X_t = Y_t + f(Z+t)$, where $Y_t$ is a Poisson Process and 
\[f(t) = t .1_{\{t \in \mathbb{Q}\}}\]
Let Z be a continuous random variable. Then we can show that $P(X_t \neq Y_t) = 0$. This is true since
\begin{flalign*}
P(X_t \neq Y_t) &= P(w \in \Omega: \quad t+Z(w) \in \mathbb{Q}) \\
&= P(Z \in \mathbb{Q} - t) = 0
\end{flalign*}
The last part follows since $\mathbb{Q}-t$ is a countable set and each event in it has probability 0.
\section{Renewal Theory}
One of the Poisson process characterization is that it's a counting process whose interarrival times were iid exponential. Now we shall relax the ``exponential" part. Thus a counting process with iid general interarrival times is called a \textbf{renewal process}. As a result, we no longer have the nice properties such as Independent/Stationary increments that Poisson Processes had. But we can still get some great results which also apply to Poisson Processes. 

Let $\{T_i: i \in \mathbb{N}\}$ be a sequence of IID random variables with a common distribution $F$. Assume 
\begin{enumerate}
	\item Finite mean i.e. $(0 \leq \mu = E[T_1] < \infty)$ and
	\item $F_n(0) = P[T_n \leq 0] = P[T_n = 0] < 1$
\end{enumerate}
Also let $S_0 = 0, S_n = \sum_{i=1}^n T_i, \quad n\in \mathbb{N}$. Note that $\{S_n \leq t\} \iff \{N(t) \geq n\}$ where $N(t) = \sum_{i=1}^\infty 1_{S_i \leq t}$.

We can also define $N(t) = \sup \{n \in \mathbb{N}:S_n \leq t \}$. Thus $\{N(t),\quad t\geq 0\}$ is called a renewal process.

\subsection{Time average of renewals}
We are interested in knowing how many renewals happen per unit time. From SLLN, we have 
\[\frac{S_n}{n} \to \mu \quad \mbox{a.s}\]

We need to know the distribution of $N(t)$. Denote $F_n = F^{*(n)}$ where $*$ denotes convolution. Essentially $F^{*(n)}$ is the distribution of $S_n$. We are interested in the following two quantities:
\begin{flalign*}
m(t) &= E[N(t)] \\
M_{N(t)}(\theta) &= E[e^{\theta N(t)}]
\end{flalign*}

\subsection{Distribution of N(t)}
We have \[P[N(t) = n] = P(S_n \leq t) - P(S_{n+1} \leq t) = F_n(t) - F_{n+1}(t)\]
\begin{Prop}
\[E[N(t)] = \sum_{n \in \mathbb{N}} F_n(t)\]
\end{Prop}
\begin{proof}
\[
E[N(t)] = \sum_{n=1}^\infty P[N(t) \geq n] = \sum_{n=1}^\infty P[S_n \leq t] = \sum_{n=1}^\infty F_n(t)
\]
\end{proof}
Alternatively one can prove the same result using indicator functions. Refer Ross for details.

\begin{Prop}
\[E[N(t) < \infty \quad \forall 0 \leq t < \infty\]
\end{Prop}
\begin{proof}
Since we assumed that $P[T_n=0] < 1$, for some $\alpha > 0$, we have $P[T_n \geq \alpha] >0$. Define
\[\overline{T}_n = \alpha 1_{\{T_n \geq \alpha\}}\]
Let $\overline{N}(t)$ denote the renewal process with interarrival times $\overline{T}_n$. Note that since $T_i$ are iid, so are $\overline{T}_i$ (Why?). In fact the arrivals now happen at multiples of $\alpha$. And yes, they stack. Moreover $T_n \geq \overline{T}_n$

The number of arrivals till time $t$, therefore is Geometric with mean $\frac{1}{P[T_n \geq \alpha]}$. Thus 
\[E[\overline{N}(t)] = \frac{\lceil\frac{t}{\alpha} \rceil + 1}{P[T_n \geq \alpha]} < \infty\]
Since $E[N(t)] \leq E[\overline{N}(t)]$ which follows from $N(t) \leq \overline{N}(t)$, we are done.
\end{proof}
End of Lecture.

Notify any typos to \url{gautamshenoydmc@gmail.com}.
\end{document}