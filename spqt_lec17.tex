\documentclass[a4paper,10pt]{article}
\usepackage{%
amsmath,%
amsfonts,%
amssymb,%
amsthm,%
hyperref,%
url,%
latexsym,%
epsfig,%
graphicx,%
psfrag,%
subfigure,%
color,%
tikz,%
pgf,%
pgfplots,%
pgfplotstable,%
pgfpages%
}
\usepgflibrary{shapes}
\usetikzlibrary{%
arrows,%
backgrounds,%
chains,%
decorations.pathmorphing,% /pgf/decoration/random steps | erste Graphik
decorations.text,%
matrix,%
positioning,% wg. " of "
fit,%
patterns,%
petri,%
plotmarks,%
scopes,%
shadows,%
shapes.misc,% wg. rounded rectangle
shapes.arrows,%
shapes.callouts,%
shapes%
}
\theoremstyle{plain}
\newtheorem{thm}{Theorem}[section]
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollary}
\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition}
\newtheorem{conj}[thm]{Conjecture}
\newtheorem{exmp}[thm]{Example}
\theoremstyle{remark}
\newtheorem{rem}[thm]{Remark}
\newtheorem{note}[thm]{Note}
\date{}
\title{Lecture 17: Martingales}
\author{Parimal Parag}
\begin{document}
\maketitle
\section{Martingales}

\begin{exmp}
\textbf{Computing the mean time until a pattern occurs:} Consider a sequence of $\textit{iid}$ random variables $\{X_n,~ n\geq 1\}$. Let $X_n$ take values $0,1,~$ or $2$ with respective probabilities  $1/2,1/3$ and $1/6$. Let $N$ denote the first time the pattern $0,2,0$ appears. We are interested in computing $E[N]$. Note that we had solved the same problem earlier using delayed renewal process theory. We shall have a fresh look at the same problem and try to solve it using martingale theory. 

Consider a sequence of gamblers , each initially having 1 unit, playing at a fair gambling casino. Gambler $i$ begins betting on $i^{\text{th}}$ day and bets the $1$ unit he has. If he wins, he bets $2$ units on the next outcome being $2$. If we wins, he will have $12$ units in his hand because he must be earning $10$ units for his bet on $2$ and the casino is fair ($-2 \times (5/6) + (10) \times( 1/6) = 0$). If he wins the second bet, he bets the 12 units that he earned on the next outcome being $0$. At third bet, he quits. At the beginning of each day, a new gambler starts playing. If $X_n$ denotes the total winnings after $n^\text{th}$ day, then since all bets are fair, it follows that $\{X_n,~n \geq 1\}$ is a martingale with mean 0. At the end of day $N$, each of the gamblers $1,2 \hdots N_3$ would have lost 1 unit; gambler $N-2$ would have won 23, gambler $N-1$ would have lost 1, and gambler $N$ would have won 1 (since the outcome on day $N$ is 0). Hence,
\begin{equation*}
X_N=N-3-23+1-1=N-26
\end{equation*}
  and, since $E[N]=0$ (Martingale stopping theorem), we see that
  \begin{equation*}
     E[N]=26.
  \end{equation*}
  In the same manner, we can find the mean number of coin tosses until a particular pattern, say, $HHTTHH$ occurs to be $p^{-4}q^{-2}+p^{-2}+p^{-1}$, where $p=Pr\{H\}=1-q$.
\end{exmp}
\begin{exmp}
\textbf{Coin exchange game:} Players $X,Y$ and $Z$ play the following game. At each stage, two of them are chosen randomly in sequence, with the first one chosen being required to give 1 coin to another. All choices are equally and successive choices are independent of the past. This continues until one of the player has no coins and he departs. The game is then continued with the remaining two players until one of them has all the coins. If the players initially has $x,~y$ and $z$ coins, find the expected number of plays until one of them has all the $s \equiv x+y+z$ coins.\\
\textit{Solution:} Let $T$ denote the game ending time. Then $T$ is the first time two players depart. Let $X_n,~Y_n$ and $Z_n$ denote the amount of money that $X,~Y$ and $Z$ have after $n^{\text{th}}$ game. Define
\begin{equation*}
M_n=X_nY_n+Y_nZ_n+Z_nX_n+n.
\end{equation*}
We will first show that $\{M_n,~n \geq 1\}$ is a martingale. To that end, observe that $M_n$ is integrable as 
\begin{equation*}
E[|M_n|] \leq x+y+z+n < \infty.
\end{equation*}
For $X_nY_nZ_n>0 :$
\begin{flalign*}
E[X_{n+1}Y_{n+1}|X_n,Y_n,Z_n]&=\frac{1}{6}E[(X_n+1)(Y_n-1)+(X_n-1)(Y_n+1)+(X_n)(Y_n+1)+\\
&(X_n)(Y_n-1)+(X_n-1)(Y_n)+(X_n+1)(Y_n)|X_n,Y_n,Z_n]\\
&=X_nY_n-\frac{1}{3}.
\end{flalign*}
Since other conditional expectations are similarly defined, we find that 
\begin{equation*}
E[M_{n+1}|X_n,Y_n,Z_n \hdots ] = M_n.
\end{equation*}
Now, when $X_nY_nZ_n=0$, i.e. when one of the players exit the game, say $X$, then
\begin{equation*}
E[Y_{n+1}Z_{n+1}|X_nY_nZ_n] = \frac{1}{2}[(Y_n+1)(X_n-1)+(Y_n-1)(X_n+1)]=Y_nZ_n-1.
\end{equation*}
Hence, in this case, we again obtain
\begin{equation*}
E[M_{n+1}|X_n,Y_n,Z_n, \hdots] = M_n.
\end{equation*}
Hence $\{M_n\}$ is a martingale. By martingale stopping theorem (third condition can be directly verified for the result to hold), 
\begin{equation*}
E[M_{T}] = E [ M_0 ].
\end{equation*}
Since two of $X_T,Y_T,Z_T$ are 0, 
\begin{equation*}
E[M_{T}] = E[T].
\end{equation*} 
Hence, 
\begin{equation*}
E[T]=E[M_{T}] = E[M_0]=xy+yz+zx.
\end{equation*}
\end{exmp}
\subsection{Azuma's Inequality for Martingales}
Azuma's inequality enables us to obtain useful bounds on the probabilities of a martingale sequence which do not vary too rapidly. 
\begin{lem}
Let $X$ be a random variable such that $E[X]=0$ and $Pr(-\alpha \leq X \leq \beta)=1$. Then for any convex function $f$
\begin{equation*}
E[f(X)] \leq \frac{\beta}{\alpha+\beta}f(-\alpha)+\frac{\alpha}{\alpha+\beta}f(\beta).
\end{equation*}
\end{lem}
\begin{proof}
Since $f(x)$ is convex the function value lies below the line segment joining $f(-\alpha)$ and $f(\beta)$. That is,
\begin{equation*}
f(x) \leq \frac{\beta}{\alpha+\beta}f(-\alpha)+\frac{\alpha}{\alpha+\beta}f(\beta)+ \frac{1}{\alpha+\beta}[f(\beta)-f(-\alpha)]x
\end{equation*}
Taking expectation on both sides gives the required result.
\end{proof}
\begin{lem}
\label{exponential lemma}
For $0 \leq \theta \leq 1$
\begin{equation*}
\theta e^{(1-\theta)x}+(1-\theta)e^{-\theta x} \leq e^{x^2/8}.
\end{equation*}
\end{lem}
\begin{proof}
Let $\theta= (1+\alpha)/2$ and $x=2\beta$, we must show that for $-1 \alpha \leq +1$, 
\begin{equation*}
(1+\alpha)e^{\beta(1-\alpha)+(1-\alpha)e^{-\beta{(1+\alpha)}}} \leq 2e^{\beta^2 /2}
\end{equation*}
or, equivalently,
\begin{equation*}
e^\beta+e^{-\beta}+\alpha(e^\beta-e^{-\beta}) \leq 2e^{\alpha\beta+\beta^2/2}.
\end{equation*}
It can be seen that the above inequality is true when $\alpha=-1$ or $\alpha=+1$ and when $\beta$ is large (say when $|\beta| \leq 100$). Thus, if the lemma were false then the function
\begin{equation*}
f(\alpha, \beta) = e^{\beta}+e^{-\beta}+\alpha(e^\beta-e^{-\beta})-2e^{\alpha\beta+\beta^2/2},
\end{equation*}
would assume a strictly positive maximum in the interior of the region $R=\{(\alpha,\beta): |\alpha|\leq 1, |\beta| \leq 100\}$. Taking the partial derivatives with respect to $\alpha$ and $\beta$ and equating to zero, we get,
\begin{eqnarray*}
&e^{\beta}-e^{-\beta}+\alpha(e^{\beta}+e^{-\beta})=2(\alpha+\beta)e^{\alpha\beta+\beta^2/2} \\
&e^{\beta}-e^{-\beta} = 2\beta e^{\alpha\beta+\beta^2/2}. 
\end{eqnarray*}
Assuming a solution in which $\beta \neq 0$ implies, upon division, that
\begin{equation*}
1+ \alpha \frac{e^{\beta}+e^{-\beta}}{e^{\beta}-e^{-\beta}}=1+\frac{\alpha}{\beta}.
\end{equation*}

By expanding in a power series $e^\beta$ and $e^{-\beta}$, there is no solution for the above equation for $\beta \neq 0,~ \alpha =0$. Hence, if the lemma is not true, we can conclude that the strictly positive maximal value of $f(\alpha,\beta)$  occurs when $\beta =0$. However, $f(\alpha, 0)=0$. Hence the lemma is proven.
\end{proof}

\begin{thm}
\textbf{Azuma's Inequality} Let $Z_n,~ n\geq 1$ be a martingale with mean $\mu= E[Z_n]$. Let $Z_0= \mu$ and suppose that for nonnegative constants $\alpha_i,~\beta_i,~ i \geq 1,$
\begin{equation*}
-\alpha_i \leq Z_i-Z_{i-1} \leq \beta_i.
\end{equation*}
Then for any $n \geq 0, ~a >0 :$
\begin{enumerate}
\item $Pr(Z_n - \mu \geq a) \leq exp\{-2a^2/ \sum_{i=1}^{n}(\alpha_i+\beta_i)^2\}.$
\item $Pr(Z_n - \mu \leq -a) \leq exp\{-2a^2/ \sum_{i=1}^{n}(\alpha_i+\beta_i)^2\}.$
\end{enumerate}
\end{thm}
Suppose first that $\mu=0$. For $c>0$
\begin{equation*}
Pr(Z_n \geq a) = Pr(exp\{cZ_n\} \geq e^{ca})
\end{equation*}
From Markov inequality, we get
\begin{equation}
\label{Markov Inequality: Azuma}
Pr(Z_n \geq a)  \leq E[exp\{cZ_n\}]e^{-ca}.
\end{equation}
Let $W_n-exp{cZ_n}$. Note that $W_0=0$ and that for $n \geq 1$
\begin{equation*}
W_n=exp\{cZ_{n-1}exp\{c(Z_n-Z_{n-1})\}\}.
\end{equation*}
Therefore, 
\begin{eqnarray*}
E[W_n|Z_{n-1}]&=exp\{cZ_{n-1}\}E[exp\{c(Z_n-Z_{n-1})\}|Z_{n-1}]\\
& \leq W_{n-1}[\beta_n exp{-c\alpha_n}+\alpha_n exp\{c\beta_n\}]/(\alpha_n+\beta_n)
\end{eqnarray*}
where the last inequality follows from Lemma \ref{exponential lemma}. Since 
\begin{enumerate}
\item $f(x) =e^{cx}$ is convex.
\item $-\alpha_i \leq Z_i-Z_{i-1} \leq \beta_i.$
\item $E[Z_i-Z_{i-1}|Z_{i-1}]=E[Z_i|Z_{i-1}]-E[Z_i|Z_{i-1}] = 0$.
\end{enumerate}
Taking expectations gives
\begin{equation*}
E[W_n] \leq E[W_{n-1}](\beta_nexp\{-c \alpha_n\}+\alpha_n exp\{c\beta_n\})/(\alpha_n+\beta_n).
\end{equation*}
Since $E[W_0]=1$, iterating the above inequality gives
\begin{equation*}
E[W_n] \leq \Pi_{i=1}^{n}\{(\beta_iexp\{-c\alpha_i\})+\alpha_i exp\{c\beta_i\})/(\alpha_i+\beta_i)\}.
\end{equation*}
Thus from Equation \ref{Markov Inequality: Azuma}, we obtain that for any $c>0$
\begin{equation}
\label{Azuma1}
Pr(Z_n \geq a ) \leq e^{-ca}\Pi_{i=1}^{n}\{(\beta_i exp\{-c\alpha_i\}+\alpha_i exp\{c\beta_i\})/(\alpha_i+\beta_i)\}
\end{equation}
Upon setting $\theta =\alpha_i/(\alpha_i+\beta_i)$ and $x=c((\alpha_i+\beta_i))$ and using Lemma \ref{exponential lemma}, we can write
\begin{equation*}
Pr(Z_n \geq a) \leq e^{-ca}\Pi_{i=1}^{n}exp\{c^2(\alpha_i+\beta_i)^2/8\}.
\end{equation*}
Thus for any $c>0$,
\begin{equation*}
Pr(Z_n \geq a) \leq exp{-ca+c^2\sum_{i=1}^{n}(\alpha_i+\beta_i)^2/8}.
\end{equation*}
Letting $c=\frac{4a}{\sum_{i=1}^n(\alpha_i+\beta_i)^2}$ (which is the value that minimizes the exponent in the above equation) gives that
\begin{equation*}
Pr(Z_n \geq a) \leq exp\{-2a^2/\sum_{i=1}^n(\alpha_i+\beta_i)^2\}.
\end{equation*}
Parts $(i)$ and $(ii)$ of Azuma's inequality now follow from applying the preceding, first to the zero-mean martingale $\{Z_n-\mu\}$ and to the zero mean martingale $\{\mu-Z_n\}$.
\begin{exmp}
Suppose that $n$ balls are put in $m$ urns in such a manner that each ball, independently, is equally likely to go into any of the bins. We would like to obtain bounds on the tail probability of the number of empty bins. Let
\begin{eqnarray*}
X&=\sum_{i=1}{n}1_\{\text{bin~} i~\text{is empty}\},\\
E[X]&=mPr(\text{bin~} i~\text{is empty})=m(1-1/m)^n \equiv \mu. 
\end{eqnarray*}
Let $X_j$ denote the bin in which $j^{\text{th}}$ ball is placed. Let $Z_0=E[X]$ and $Z_i=E[X|X_1,X_2 \hdots X_i]$. Note that $Z_n$ sequence forms a Doob's martingale sequence. Also, observe that $|Z_1-Z_0|=0$. Let $D$ denote the number of distinct values in $X_1 \hdots X_{i-1}$. Thus $D$ denotes the number of bins which have at least one  ball in it after having distributed $i-1$ balls. Each of the $m-D$ empty bins will end up empty with probability $(1-1/m)^{n-i+1}$. Hence we have
\begin{equation*}
E[X|X_1 \hdots X_{i-1}]=(m-D)(1-1/m)^{n-i+1}.
\end{equation*}
We have,
\begin{eqnarray*}
E[X_i|X_1 \hdots X_{i-1}] =
\begin{cases}
(m-D)(1-1/m)^{n-i}, & \text{if} X_i \in (X_1 \hdots X_{i-1}) \\
(m-D-1)(1-1/m)^{n-i} , & \text{if} X_i \notin (X_1 \hdots X_{i-1}).
\end{cases}
\end{eqnarray*}
Hence, for $i \geq 2$, $Z_i-Z_{i-1}$ are
\begin{eqnarray*}
\frac{(m-D)}{m}(1-1/m)^{n-i} ~\text{and}~ \frac{(-D)}{m}(1-1/m)^{n-i}.
\end{eqnarray*}
Since $1 \leq D \leq \min\{i-1,m\}$, we thus obtain that 
\begin{equation*}
-\alpha_i \leq Z_i-Z_{i-1} \leq \beta_i,
\end{equation*}
where
\begin{equation*}
\alpha_i =\min(\frac{i-1}{m},1)(1-1/m)^{n-i},~\beta_i=(1-1/m)^{n-i+1}.
\end{equation*}
From Azuma's inequality we thus obtain that for $a>0$
\begin{equation*}
Pr(X-\mu \geq a) \leq exp\{-2a^2/\sum_{i=2}^n(\alpha_i+\beta_i)^2\},
\end{equation*}
where 
\begin{equation*}
\sum_{i=2}^{n}(\alpha_i+\beta_i)^2=\sum_{i=2}^{n}(m+i-2)^2(1-1/m)^{2(n-1)}/m^2+\sum_{i=m+2}^{n}(1-1/m)^2(2-1/m)^2.
\end{equation*}
\end{exmp}
Azuma's inequality is generally used in conjunction with Doob's inequality for which $|Z_i-Z_{i-1}| \leq 1$. The following corollory gives a sufficient condition  for Doob type martingale to satisfy the condition.
\begin{cor}
Let $h$ be a function such that if the vectors $\textbf{x}=(x_1,x_2 \hdots x_n)$ and $\textbf{y}=(y_1,y_2 \hdots y_n)$ differ in at most one coordinate, then $|h(x)-h(y)| \leq 1$. Let $X_1,X_2 \hdots X_n$ be independent random variables. Then, with $\textbf{X}=(X_1 \hdots X_n)$ we have for a >0 that
\begin{enumerate}
\item $Pr(h(\textbf{X})-E[h(\textbf{X})] \geq a) \leq e^{-a^2/2n}$.
\item $Pr(h(\textbf{X})-E[h(\textbf{X})] \leq -a) \leq e^{-a^2/2n}$
\end{enumerate}
\end{cor}
\begin{proof}
Consider the martingale 
\begin{equation*}
Z_i =E[h(\textbf{h(X)})|\textbf{X}_1 \hdots \textbf{X}_i],~ i=1, \hdots , n.
\end{equation*}
Now, 
\begin{eqnarray*}
&|E[h(\textbf{h(X)})|\textbf{X}_1 \hdots \textbf{X}_i]-E[h(\textbf{h(X)})|\textbf{X}_1 \hdots \textbf{X}_{i-1}]|\\
&=|E[h(x_1,\hdots x_i,X_{i+1}, \hdots ,X_n)]-E[h(x_1,\hdots x_{i-1},X_{i}, \hdots ,X_n)]|\\
&=|E[h(x_1,\hdots x_i,X_{i+1}, \hdots ,X_n)-h(x_1,\hdots x_{i-1},X_{i}, \hdots ,X_n)]|
\end{eqnarray*}
Hence, $|Z_i-Z_{i-1}|\leq 1$ and so the result follows from Azuma's inequality with $\alpha_i=\beta_i=1$.
\end{proof}

\end{document}